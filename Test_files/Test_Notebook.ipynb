{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    " # Example of one output for whole sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# define model where LSTM is also output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array253 = np.arange(0, 253, 1).tolist()\n",
    "array_253 = np.array(array253)\n",
    "array_253 = array_253.reshape(-1,1)\n",
    "np.shape(array_253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VMW = pd.read_csv(\"VMW.csv\")\n",
    "VMW = pd.read_csv(\"VMW2.csv\")\n",
    "VMW_open = VMW['Open']\n",
    "VMW_array_ = VMW['Open'].to_numpy()\n",
    "VMW_array = VMW_array_.reshape(-1,1)\n",
    "np.shape(VMW_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1, return_sequences = True, input_shape=(253,1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# input time steps\n",
    "data = array_253.reshape((1,253,1))\n",
    "#data = array([0.1, 0.2, 0.3,0.4,0.5,0.6,0.7]).reshape((1,7,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>166.330002</td>\n",
       "      <td>169.330002</td>\n",
       "      <td>166.179993</td>\n",
       "      <td>167.970001</td>\n",
       "      <td>167.970001</td>\n",
       "      <td>1115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>166.820007</td>\n",
       "      <td>168.500000</td>\n",
       "      <td>165.369995</td>\n",
       "      <td>165.830002</td>\n",
       "      <td>165.830002</td>\n",
       "      <td>812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>164.830002</td>\n",
       "      <td>166.610001</td>\n",
       "      <td>163.509995</td>\n",
       "      <td>165.949997</td>\n",
       "      <td>165.949997</td>\n",
       "      <td>724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>167.339996</td>\n",
       "      <td>168.770004</td>\n",
       "      <td>165.570007</td>\n",
       "      <td>168.369995</td>\n",
       "      <td>168.369995</td>\n",
       "      <td>720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.779999</td>\n",
       "      <td>166.470001</td>\n",
       "      <td>167.360001</td>\n",
       "      <td>167.360001</td>\n",
       "      <td>892500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>136.779999</td>\n",
       "      <td>140.979996</td>\n",
       "      <td>136.429993</td>\n",
       "      <td>140.740005</td>\n",
       "      <td>140.740005</td>\n",
       "      <td>1161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>141.220001</td>\n",
       "      <td>141.619995</td>\n",
       "      <td>138.869995</td>\n",
       "      <td>140.289993</td>\n",
       "      <td>140.289993</td>\n",
       "      <td>625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>144.990005</td>\n",
       "      <td>146.220001</td>\n",
       "      <td>140.860001</td>\n",
       "      <td>140.860001</td>\n",
       "      <td>140.860001</td>\n",
       "      <td>1133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>140.800003</td>\n",
       "      <td>141.830002</td>\n",
       "      <td>136.809998</td>\n",
       "      <td>139.949997</td>\n",
       "      <td>139.949997</td>\n",
       "      <td>927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>141.679993</td>\n",
       "      <td>142.580002</td>\n",
       "      <td>140.300003</td>\n",
       "      <td>140.559998</td>\n",
       "      <td>140.559998</td>\n",
       "      <td>838400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2019-11-12  166.330002  169.330002  166.179993  167.970001  167.970001   \n",
       "1    2019-11-13  166.820007  168.500000  165.369995  165.830002  165.830002   \n",
       "2    2019-11-14  164.830002  166.610001  163.509995  165.949997  165.949997   \n",
       "3    2019-11-15  167.339996  168.770004  165.570007  168.369995  168.369995   \n",
       "4    2019-11-18  168.000000  168.779999  166.470001  167.360001  167.360001   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "248  2020-11-05  136.779999  140.979996  136.429993  140.740005  140.740005   \n",
       "249  2020-11-06  141.220001  141.619995  138.869995  140.289993  140.289993   \n",
       "250  2020-11-09  144.990005  146.220001  140.860001  140.860001  140.860001   \n",
       "251  2020-11-10  140.800003  141.830002  136.809998  139.949997  139.949997   \n",
       "252  2020-11-11  141.679993  142.580002  140.300003  140.559998  140.559998   \n",
       "\n",
       "      Volume  \n",
       "0    1115300  \n",
       "1     812900  \n",
       "2     724800  \n",
       "3     720800  \n",
       "4     892500  \n",
       "..       ...  \n",
       "248  1161400  \n",
       "249   625400  \n",
       "250  1133900  \n",
       "251   927900  \n",
       "252   838400  \n",
       "\n",
       "[253 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "VMW = pd.read_csv(\"VMW.csv\")\n",
    "VMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open shape\n",
      "(253, 1)\n",
      "Close shape\n",
      "(253, 1)\n"
     ]
    }
   ],
   "source": [
    "#Shape Data\n",
    "VMW = pd.read_csv(\"VMW.csv\")\n",
    "VMW_open = VMW['Open'].to_numpy()\n",
    "X = VMW_open.reshape(-1,1)\n",
    "print(\"Open shape\")\n",
    "print(np.shape(X))\n",
    "VMW_close = VMW['Close'].to_numpy()\n",
    "y = VMW_close.reshape(-1,1)\n",
    "print(\"Close shape\")\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(1,253,1)\n",
    "y = y.reshape(1,253,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(2))\n",
    "model.add(Dense(1))\n",
    "#model.add(Activation('sigmod'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples\n",
      "Epoch 1/60\n",
      "1/1 - 5s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 2/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 3/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 4/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 5/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 6/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 7/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 8/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 9/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 10/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 11/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 12/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 13/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 14/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 15/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 16/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 17/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 18/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 19/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 20/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 21/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 22/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 23/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 24/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 25/60\n",
      "1/1 - 1s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 26/60\n",
      "1/1 - 1s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 27/60\n",
      "1/1 - 1s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 28/60\n",
      "1/1 - 1s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 29/60\n",
      "1/1 - 1s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 30/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 31/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 32/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 33/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 34/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 35/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 36/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 37/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 38/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 39/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 40/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 41/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 42/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 43/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 44/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 45/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 46/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 47/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 48/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 49/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 50/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 51/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 52/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 53/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 54/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 55/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 56/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 57/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 58/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 59/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n",
      "Epoch 60/60\n",
      "1/1 - 0s - loss: 20056.6953 - mean_squared_error: 20056.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb464a8b5d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model\n",
    "#model.fit(X, y, batch_size=10, epoch=100)\n",
    "model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/sample - loss: 20056.6953 - mean_squared_error: 20056.6953\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
